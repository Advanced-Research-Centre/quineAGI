{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Phase 3: Spiking Neural Networks in TensorFlow </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaky integrate and fire neuron with Tensorflow\n",
    "\n",
    "Spiking Neural Networks (SNN) are the next generation of neural networks, that operate using spikes, which are discrete events that take place at points in time, rather than continuous values. Once a stimulated neuron reaches a certain potential, it spikes, and the potential of that neuron is reset. \n",
    "\n",
    "The [leaky integrate-and-fire](http://lcn.epfl.ch/~gerstner/SPNM/node26.html#SECTION02311000000000000000) (LIF) neuron is one of the simplest spiking neuron models, but it is still very popular due to the ease with which it can be analyzed and simulated.\n",
    "\n",
    "The basic circuit of an integrate-and-fire model consists of a capacitor C in parallel with a resistor R driven by a current I(t):\n",
    "\n",
    "<img src=\"http://lcn.epfl.ch/~gerstner/SPNM/img378.gif\" alt=\"LIF Model\" style=\"width: 350px;\"/>\n",
    "\n",
    "The driving current can be split into two components, $I(t) = I_R + I_C$. \n",
    "\n",
    "The first component, the resistive current $I_R$, passes through the linear resistor $R$. From Ohm's law, $I_R = \\frac{v}{R}$, where $v$ is the voltage across the resistor.\n",
    "\n",
    "The second component $I_C$ charges the capacitor $C = \\frac{q}{v}$ (where $q$ is the charge and $u$ the voltage). So the capacitive current $I_C = C\\frac{dv}{dt}$.\n",
    "\n",
    "Multiplying the equation by $R$ and introducing the time constant $\\tau_{m} = RC$ yields the standard form:\n",
    "\n",
    "$$\\tau_{m}\\frac{dv}{dt}=-v(t) + RI(t)$$\n",
    "\n",
    "where $v(t)$ represents the membrane potential at time $t$, $\\tau_{m}$ is the membrane time constant and $R$ is the\n",
    "membrane resistance.\n",
    "\n",
    "When the membrane potential reaches the spiking threshold $v_{thresh}$, the neuron 'spikes' and enters a resting state for a duration $\\tau_{rest}$. During the resting period the membrane potential remains constant a $v_{rest}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A basic LIF neuron\n",
    "class LIFNeuron(object):\n",
    "    \n",
    "    def __init__(self, u_rest=0.0, u_thresh=1.0, tau_rest=4.0, r=1.0, tau=10.0):\n",
    "        \n",
    "        # Membrane resting potential in mV\n",
    "        self.u_rest = u_rest\n",
    "        # Membrane threshold potential in mV\n",
    "        self.u_thresh = u_thresh\n",
    "        # Duration of the resting period in ms\n",
    "        self.tau_rest = tau_rest\n",
    "        # Membrane resistance in Ohm\n",
    "        self.r = r\n",
    "        # Membrane time constant in ms\n",
    "        self.tau = tau\n",
    "        \n",
    "        # Instantiate a graph for this neuron\n",
    "        self.graph = tf.Graph()\n",
    "        \n",
    "        # Build the graph\n",
    "        with self.graph.as_default():\n",
    "        \n",
    "            # Initialize variables and placeholders\n",
    "            self.get_vars_and_ph()\n",
    "            \n",
    "            # Operations\n",
    "            self.input = self.get_input_op()\n",
    "            self.potential = self.get_potential_op()\n",
    "            # Note that input is a prerequisite of potential, so it will\n",
    "            # always be evaluated when potential is\n",
    "            \n",
    "    # Variables and placeholders\n",
    "    def get_vars_and_ph(self):\n",
    "\n",
    "        # The current membrane potential\n",
    "        self.u = tf.Variable(self.u_rest, dtype=tf.float32, name='u')\n",
    "        # The duration left in the resting period (0 most of the time except after a neuron spike)\n",
    "        self.t_rest = tf.Variable(0.0, dtype=tf.float32, name='t_rest')\n",
    "        # Input current\n",
    "        self.i_app = tf.placeholder(dtype=tf.float32, name='i_app')\n",
    "        # The chosen time interval for the stimulation in ms\n",
    "        self.dt = tf.placeholder(dtype=tf.float32, name='dt')\n",
    "\n",
    "    # Evaluate input current\n",
    "    def get_input_op(self):\n",
    "        \n",
    "        return self.i_app\n",
    "        \n",
    "    # Neuron behaviour during integration phase (below threshold)\n",
    "    def get_integrating_op(self):\n",
    "\n",
    "        # Get input current\n",
    "        i_op = self.get_input_op()\n",
    "\n",
    "        # Update membrane potential\n",
    "        du_op = tf.divide(tf.subtract(tf.multiply(self.r, i_op), self.u), self.tau) \n",
    "        u_op = self.u.assign_add(du_op * self.dt)\n",
    "        # Refractory period is 0\n",
    "        t_rest_op = self.t_rest.assign(0.0)\n",
    "        \n",
    "        with tf.control_dependencies([t_rest_op]):\n",
    "            return u_op\n",
    "\n",
    "    # Neuron behaviour during firing phase (above threshold)    \n",
    "    def get_firing_op(self):                  \n",
    "\n",
    "        # Reset membrane potential\n",
    "        u_op = self.u.assign(self.u_rest)\n",
    "        # Refractory period starts now\n",
    "        t_rest_op = self.t_rest.assign(self.tau_rest)\n",
    "\n",
    "        with tf.control_dependencies([t_rest_op]):\n",
    "            return u_op\n",
    "\n",
    "    # Neuron behaviour during resting phase (t_rest > 0)\n",
    "    def get_resting_op(self):\n",
    "\n",
    "        # Membrane potential stays at u_rest\n",
    "        u_op = self.u.assign(self.u_rest)\n",
    "        # Refractory period is decreased by dt\n",
    "        t_rest_op = self.t_rest.assign_sub(self.dt)\n",
    "        \n",
    "        with tf.control_dependencies([t_rest_op]):\n",
    "            return u_op\n",
    "\n",
    "    def get_potential_op(self):\n",
    "        \n",
    "        return tf.case(\n",
    "            [\n",
    "                (self.t_rest > 0.0, self.get_resting_op),\n",
    "                (self.u > self.u_thresh, self.get_firing_op),\n",
    "            ],\n",
    "            default=self.get_integrating_op\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation with square input currents\n",
    "\n",
    "# Duration of the simulation in ms\n",
    "T = 200\n",
    "# Duration of each time step in ms\n",
    "dt = 0.5\n",
    "# Number of iterations = T/dt\n",
    "steps = int(T / dt)\n",
    "# Output variables\n",
    "I = []\n",
    "U = []\n",
    "\n",
    "neuron = LIFNeuron()\n",
    "    \n",
    "with tf.Session(graph=neuron.graph) as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())    \n",
    "\n",
    "    for step in range(steps):\n",
    "        \n",
    "        t = step * dt\n",
    "        # Set input current in mA\n",
    "        if t > 10 and t < 30:\n",
    "            i_app = 0.5\n",
    "        elif t > 50 and t < 100:\n",
    "            i_app = 1.2\n",
    "        elif t > 120 and t < 180:\n",
    "            i_app = 1.5\n",
    "        else:\n",
    "            i_app = 0.0\n",
    "\n",
    "        feed = { neuron.i_app: i_app, neuron.dt: dt}\n",
    "        \n",
    "        u = sess.run(neuron.potential, feed_dict=feed)\n",
    "\n",
    "        I.append(i_app)\n",
    "        U.append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] =(4,2)\n",
    "# Draw the input current and the membrane potential\n",
    "plt.figure()\n",
    "plt.plot([i for i in I])\n",
    "plt.title('Square input stimuli')\n",
    "plt.ylabel('Input current (I)')\n",
    "plt.xlabel('Time (msec)')\n",
    "plt.figure()\n",
    "plt.plot([u for u in U])\n",
    "plt.axhline(y=1.0, color='r', linestyle='-')\n",
    "plt.title('LIF response')\n",
    "plt.ylabel('Membrane Potential (mV)')\n",
    "plt.xlabel('Time (msec)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation with random input currents\n",
    "\n",
    "T = 200\n",
    "dt = 1\n",
    "steps = int(T / dt)\n",
    "I = []\n",
    "U = []\n",
    "neuron = LIFNeuron()\n",
    "with tf.Session(graph=neuron.graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())    \n",
    "    for step in range(steps):\n",
    "        t = step * dt\n",
    "        if t > 10 and t < 180:\n",
    "            i_app = np.random.normal(1.5, 1.0)\n",
    "        else:\n",
    "            i_app = 0.0\n",
    "\n",
    "        feed = { neuron.i_app: i_app, neuron.dt: dt}\n",
    "        \n",
    "        u = sess.run(neuron.potential, feed_dict=feed)\n",
    "        I.append(i_app)\n",
    "        U.append(u)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] =(4,2)\n",
    "# Draw the input current and the membrane potential\n",
    "plt.figure()\n",
    "plt.plot([i for i in I])\n",
    "plt.title('Square input stimuli')\n",
    "plt.ylabel('Input current (I)')\n",
    "plt.xlabel('Time (msec)')\n",
    "plt.figure()\n",
    "plt.plot([u for u in U])\n",
    "plt.axhline(y=1.0, color='r', linestyle='-')\n",
    "plt.title('LIF response')\n",
    "plt.ylabel('Membrane Potential (mV)')\n",
    "plt.xlabel('Time (msec)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stimulate neuron with synaptic currents\n",
    "\n",
    "Assume that the neuron is connected to input neurons through $m$ synapses. The contribution of the synapses to the neuron input current is given by the general formula below:\n",
    "\n",
    "$$I =\\sum_{i}^{}\\Big(w_{i}*\\big(\\sum_{f}{}I_{syn}(t-t_i^{(f)})\\big)\\Big)$$\n",
    "\n",
    "Where $t_i^{(f)}$ is the time of the f-th spike of the synapse $i$.\n",
    "\n",
    "A typical implementation of the $I_{syn}$ function is:\n",
    "\n",
    "$$I_{syn}(t)=\\frac{q}{\\tau_{syn}}exp(-\\frac{t}{\\tau_{syn}})$$\n",
    "\n",
    "where $q$ is the total charge that is injected in a postsynaptic neuron via a synapse with efficacy $w_{j} = 1$.\n",
    "\n",
    "Note that $\\frac{dI_{syn}}{dt}=-\\frac{I_{syn}(t)}{\\tau_{syn}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIF neuron that takes synaptic spikes as input and remember them over a specified time period\n",
    "class LIFSynapticNeuron(LIFNeuron):\n",
    "    \n",
    "    def __init__(self, n_nrn, n_syn, w, max_spikes=1, u_rest=0.0, u_thresh=1.0, tau_rest=4.0, r=1.0, tau=10.0, q=1.5, tau_syn=10.0):\n",
    "      \n",
    "        # Number of synapses\n",
    "        self.n_syn = n_syn\n",
    "        # Maximum number of spikes we remember\n",
    "        self.max_spikes = max_spikes\n",
    "        # The neuron synaptic 'charge'\n",
    "        self.q = q\n",
    "        # The synaptic time constant (ms)\n",
    "        self.tau_syn = tau_syn\n",
    "        # The synaptic efficacy\n",
    "        self.w = w\n",
    "\n",
    "        super(LIFSynapticNeuron, self).__init__(u_rest, u_thresh, tau_rest, r, tau)\n",
    "    \n",
    "    # Update the parent graph variables and placeholders\n",
    "    def get_vars_and_ph(self):\n",
    "        \n",
    "        # Get parent grah variables and placeholders\n",
    "        super(LIFSynapticNeuron, self).get_vars_and_ph()\n",
    "\n",
    "        # Add ours\n",
    "        \n",
    "        # The history of synaptic spike times for the neuron \n",
    "        self.t_spikes = tf.Variable(tf.constant(-1.0, shape=[self.max_spikes, self.n_syn], dtype=tf.float32))\n",
    "        # The last index used to insert spike times\n",
    "        self.t_spikes_idx = tf.Variable(self.max_spikes-1, dtype=tf.int32)\n",
    "        # A placeholder indicating which synapse spiked in the last time step\n",
    "        self.syn_has_spiked = tf.placeholder(shape=[self.n_syn], dtype=tf.bool)\n",
    "\n",
    "    # Operation to update spike times\n",
    "    def update_spike_times(self):\n",
    "        \n",
    "        # Increase the age of older spikes\n",
    "        old_spikes_op = self.t_spikes.assign_add(tf.where(self.t_spikes >=0,\n",
    "                                                          tf.constant(1.0, shape=[self.max_spikes, self.n_syn]) * self.dt,\n",
    "                                                          tf.zeros([self.max_spikes, self.n_syn])))\n",
    "\n",
    "        # Increment last spike index (modulo max_spikes)\n",
    "        new_idx_op = self.t_spikes_idx.assign(tf.mod(self.t_spikes_idx + 1, self.max_spikes))\n",
    "\n",
    "        # Create a list of coordinates to insert the new spikes\n",
    "        idx_op = tf.constant(1, shape=[self.n_syn], dtype=tf.int32) * new_idx_op\n",
    "        coord_op = tf.stack([idx_op, tf.range(self.n_syn)], axis=1)\n",
    "\n",
    "        # Create a vector of new spike times (non-spikes are assigned a negative time)\n",
    "        new_spikes_op = tf.where(self.syn_has_spiked,\n",
    "                                 tf.constant(0.0, shape=[self.n_syn]),\n",
    "                                 tf.constant(-1.0, shape=[self.n_syn]))\n",
    "        \n",
    "        # Replace older spikes by new ones\n",
    "        return tf.scatter_nd_update(old_spikes_op, coord_op, new_spikes_op)\n",
    "\n",
    "    # Override parent get_input_op method\n",
    "    def get_input_op(self):\n",
    "        \n",
    "        # Update our memory of spike times with the new spikes\n",
    "        t_spikes_op = self.update_spike_times()\n",
    "\n",
    "        # Evaluate synaptic input current for each spike on each synapse\n",
    "        i_syn_op = tf.where(t_spikes_op >=0,\n",
    "                            self.q/self.tau_syn * tf.exp(tf.negative(t_spikes_op/self.tau_syn)),\n",
    "                            t_spikes_op*0.0)\n",
    "\n",
    "        # Add each synaptic current to the input current\n",
    "        i_op =  tf.reduce_sum(self.w * i_syn_op)\n",
    "        \n",
    "        return tf.add(self.i_app, i_op)                             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each synapse spikes according to an independent poisson process at $\\lambda = 20 Hz$.\n",
    "\n",
    "At every time step, if a single sample $r$ from a uniform distribution in the $[0,1]$ interval is lower than\n",
    "the probability of a spike over the time interval (i.e. $r < \\lambda.dt$) then a spike occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 200 # Duration of the simulation in ms\n",
    "dt = 1 # Duration of each time step in ms\n",
    "steps = int(T / dt) # Number of iterations = T/dt\n",
    "n_syn = 25 # Number of synapses\n",
    "f = 20 # Spiking frequency in Hz\n",
    "syn_has_spiked = np.full((steps,n_syn), False) # We need to keep track of input spikes over time (for plot 1)\n",
    "W = np.random.normal(1.0, 0.5, size=n_syn) # We define the synaptic efficacy as a random vector\n",
    "I = []\n",
    "U = []\n",
    "\n",
    "# Note that in practice, a much shorter period is required as the contribution of each synapse decreases very rapidly\n",
    "neuron = LIFSynapticNeuron(n_nrn=1, n_syn=n_syn, w=W, max_spikes=20)\n",
    "with tf.Session(graph=neuron.graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())    \n",
    "    for step in range(steps):\n",
    "        t = step * dt\n",
    "        if t > 10 and t < 180:\n",
    "            r = np.random.uniform(0,1, size=(n_syn))\n",
    "            syn_has_spiked[step,:] = r < f * dt * 1e-3  # Poisson Process\n",
    "        feed = { neuron.i_app: 0.0, neuron.syn_has_spiked: syn_has_spiked[step], neuron.dt: dt}\n",
    "        i, u = sess.run([neuron.input, neuron.potential], feed_dict=feed)\n",
    "        I.append(i)\n",
    "        U.append(u)\n",
    "        \n",
    "plt.rcParams[\"figure.figsize\"] =(4,2)\n",
    "# Draw spikes\n",
    "spikes = np.argwhere(syn_has_spiked)\n",
    "t, s = spikes.T\n",
    "plt.figure()\n",
    "plt.axis([0, T, 0, n_syn])\n",
    "plt.title('Synaptic spikes')\n",
    "plt.ylabel('spikes')\n",
    "plt.xlabel('Time (msec)')\n",
    "plt.scatter(t, s)\n",
    "# Draw the input current and the membrane potential\n",
    "plt.figure()\n",
    "plt.plot([i for i in I])\n",
    "plt.title('Synaptic input')\n",
    "plt.ylabel('Input current (I)')\n",
    "plt.xlabel('Time (msec)')\n",
    "plt.figure()\n",
    "plt.plot([u for u in U])\n",
    "plt.axhline(y=1.0, color='r', linestyle='-')\n",
    "plt.title('LIF response')\n",
    "plt.ylabel('Membrane Potential (mV)')\n",
    "plt.xlabel('Time (msec)')       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
